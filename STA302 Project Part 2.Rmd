---
title: "STA302 Project Part 2"
output: pdf_document
date: "2025-11-25"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# ------------------ 1) Load libraries ------------------
library(tidyverse)
library(broom)
library(car)
library(MASS)
library(ggplot2)
library(leaps)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
# ------------------ 2) Load and clean data ------------------
spotify <- read_csv("spotify-2023.csv")

predictors <- c("in_spotify_playlists", "danceability_pct", "energy_pct",
                "valence_pct", "artist_count", "released_year")

spotify <- spotify %>%
  rename_with(~ gsub("%", "pct", .x, fixed = TRUE)) %>%
  rename_with(~ make.names(.x)) %>%
  mutate(
    streams = as.numeric(streams),
    in_spotify_playlists = as.numeric(in_spotify_playlists),
    danceability_pct = as.numeric(danceability_pct),
    energy_pct = as.numeric(energy_pct),
    valence_pct = as.numeric(valence_pct),
    artist_count = as.integer(artist_count),
    released_year = as.integer(released_year)
  ) %>%
  drop_na(all_of(c("streams", predictors))) %>%
  mutate(log_streams = log1p(streams))

# ------------------ 3) Helper function: residual diagnostics ------------------
plot_residuals <- function(model, model_name, data, predictors=NULL) {
  resid_dat <- augment(model)
  
  # Add predictors
  if(!is.null(predictors)){
    preds_existing <- predictors[predictors %in% colnames(data)]
    resid_dat <- bind_cols(resid_dat, data[, preds_existing])
  }
  
  n <- nrow(resid_dat)
  p <- length(coef(model)) - 1
  resid_dat <- resid_dat %>%
    mutate(
      std_resid = rstandard(model),
      leverage = hatvalues(model),
      cooks_d = cooks.distance(model),
      outlier = abs(std_resid) > 4,
      high_leverage = leverage > 2*(p+1)/n,
      influential = cooks_d > qf(0.5, p+1, n-p-1),
      problematic = outlier | high_leverage | influential
    )
  
  # Residuals vs Fitted
  p1 <- ggplot(resid_dat, aes(x = .fitted, y = .resid)) +
    geom_point(aes(color = problematic), alpha = 0.5) +
    geom_hline(yintercept = 0, linetype=2) +
    labs(title=paste("Residuals vs Fitted:", model_name), x="Fitted", y="Residuals") +
    theme_minimal() +
    scale_color_manual(values=c("black","red"))
  
  # Histogram
  p2 <- ggplot(resid_dat, aes(x = std_resid)) +
    geom_histogram(bins=50, fill="skyblue", color="black", alpha=0.7) +
    labs(title=paste("Histogram Std Residuals:", model_name), x="Std Residuals", y="Count") +
    theme_minimal()
  
  # QQ plot
  p3 <- ggplot(resid_dat, aes(sample = .resid)) + stat_qq() + stat_qq_line() +
    labs(title=paste("QQ Plot:", model_name)) + theme_minimal()
  
  # Scale-location
  p4 <- ggplot(resid_dat, aes(x = .fitted, y = sqrt(abs(.resid)))) +
    geom_point(aes(color=problematic), alpha=0.5) +
    geom_smooth(method="loess", se=FALSE) +
    labs(title=paste("Scale-Location:", model_name), x="Fitted", y="Sqrt(|Residuals|)") +
    theme_minimal() +
    scale_color_manual(values=c("black","red"))
  
  # Optional: Residuals vs predictors
  if(!is.null(predictors)){
    for(pred in predictors){
      if(pred %in% colnames(resid_dat)){
        p_pred <- ggplot(resid_dat, aes_string(x=pred, y=".resid")) +
          geom_point(aes(color=problematic), alpha=0.5) +
          geom_smooth(method="loess", se=FALSE) +
          labs(title=paste("Residuals vs", pred, ":", model_name), x=pred, y="Residuals") +
          theme_minimal() +
          scale_color_manual(values=c("black","red"))
      }
    }
  }
  
  return(resid_dat)
}

# ------------------ 4) Step 1: Raw Y ------------------
model_raw <- lm(streams ~ in_spotify_playlists + danceability_pct + energy_pct +
                  valence_pct + artist_count + released_year +
                  danceability_pct*energy_pct, data=spotify)
resid_raw <- plot_residuals(model_raw, "raw", spotify, predictors)

# ------------------ 5) Step 2: Log Y ------------------
model_log <- lm(log_streams ~ in_spotify_playlists + danceability_pct + energy_pct +
                  valence_pct + artist_count + released_year +
                  danceability_pct*energy_pct, data=spotify)
resid_log <- plot_residuals(model_log, "logy", spotify, predictors)

# ------------------ 6) Step 3: Box-Cox on X ------------------
# Safe base-R selection
predictors_existing <- predictors[predictors %in% colnames(spotify)]
x_candidates <- spotify[, predictors_existing] %>%
  mutate_all(~ifelse(. <= 0, NA, .)) %>% drop_na()

# PowerTransform
bc_x <- tryCatch(powerTransform(as.matrix(x_candidates)), error=function(e) e)
if(!inherits(bc_x,"error")) summary(bc_x)

# Apply transformations
spotify <- spotify %>%
  mutate(
    log_in_spotify_playlists = log1p(in_spotify_playlists),
    log_danceability_pct = log1p(danceability_pct),
    log_energy_pct = log1p(energy_pct),
    sqrt_valence_pct = sqrt(valence_pct),
    inv_artist_count = 1/artist_count,
    log_released_year = log(released_year),
    log_interaction = log1p(danceability_pct*energy_pct)
  )

# ------------------ 7) Step 4: Log Y + X-transform ------------------
model_logx <- lm(log_streams ~ log_in_spotify_playlists + log_danceability_pct + log_energy_pct +
                   sqrt_valence_pct + inv_artist_count + log_released_year + log_interaction,
                 data=spotify)
resid_logx <- plot_residuals(model_logx, "logy_xtrans", spotify, predictors)

# ------------------ 8) Step 5: Quadratic ------------------
model_quad <- lm(log_streams ~ (log_in_spotify_playlists + log_danceability_pct + log_energy_pct +
                                  sqrt_valence_pct + inv_artist_count + log_released_year + log_interaction)^2,
                 data=spotify)
resid_quad <- plot_residuals(model_quad, "quad", spotify, predictors)

# ------------------ 9) Problematic points ------------------
problematic_summary <- resid_quad %>%
  summarize(
    n_outliers = sum(outlier),
    n_high_leverage = sum(high_leverage),
    n_influential = sum(influential)
  )
print(problematic_summary)

# ------------------ 10) Model selection ------------------
full_formula <- as.formula(log_streams ~ log_in_spotify_playlists + log_danceability_pct + log_energy_pct +
                             sqrt_valence_pct + inv_artist_count + log_released_year + log_interaction)
subset_model <- regsubsets(full_formula, data=spotify, nvmax=7, nbest=1, method="exhaustive")
subset_summary <- summary(subset_model)
best_adjR2 <- data.frame(
  size = 1:length(subset_summary$which[,1]),
  adjR2 = subset_summary$adjr2,
  which_vars = apply(subset_summary$which, 1, function(x) paste(names(x)[x][-1], collapse=", "))
) %>% arrange(desc(adjR2))
print(best_adjR2)

# Stepwise
full_model <- lm(full_formula, data=spotify)
intercept_model <- lm(log_streams ~ 1, data=spotify)
model_stepwise <- stepAIC(intercept_model,
                           scope=list(lower=intercept_model, upper=full_model),
                           direction="both", trace=FALSE)

# ------------------ 11) Train/test split ------------------
set.seed(123)
train_idx <- sample(seq_len(nrow(spotify)), size = floor(0.7*nrow(spotify)))
spotify_train <- spotify[train_idx, ]
spotify_test <- spotify[-train_idx, ]

preferred_train <- lm(formula(model_stepwise), data=spotify_train)
resid_train <- plot_residuals(preferred_train, "train", spotify_train, predictors)

preferred_test <- lm(formula(model_stepwise), data=spotify_test)
resid_test <- plot_residuals(preferred_test, "test", spotify_test, predictors)

# ------------------ 12) Training/Test comparison ------------------
adj_r2_train <- summary(preferred_train)$adj.r.squared
adj_r2_test <- summary(preferred_test)$adj.r.squared

coef_train <- coef(summary(preferred_train))
coef_test <- coef(summary(preferred_test))
coef_compare <- cbind(
  estimate_train = coef_train[, "Estimate"],
  se_train = coef_train[, "Std. Error"],
  estimate_test = coef_test[, "Estimate"],
  se_test = coef_test[, "Std. Error"]
) %>% as.data.frame() %>% mutate(within_2SE = abs(estimate_train - estimate_test) <= 2*se_train)
print(coef_compare)

# MSE
mse_train <- mean(residuals(preferred_train)^2)
mse_test <- mean(residuals(preferred_test)^2)
cat("MSE Train:", mse_train, "MSE Test:", mse_test, "\n")

# LOOCV
X_train <- model.matrix(preferred_train)
y_train <- spotify_train$log_streams
hat_train <- hatvalues(preferred_train)
y_hat <- fitted(preferred_train)
loocv_mse <- mean((y_train - y_hat/(1-hat_train))^2)
cat("LOOCV MSE (train):", loocv_mse, "\n")

# ------------------ 13) Coefficient table for preferred model ------------------
library(broom)
library(readr)
library(forcats)
library(ggplot2)

# ------------------ Coefficient table for model_quad ------------------
coef_table_quad <- broom::tidy(model_quad)  # tidy the model

# Round numbers and select key columns
coef_table_quad <- coef_table_quad %>%
  mutate(
    estimate = round(estimate, 3),
    std.error = round(std.error, 3),
    statistic = round(statistic, 3),
    p.value = signif(p.value, 3)
  ) %>%
  as.data.frame()  # make sure it's a clean data frame

# Print table
print(coef_table_quad)

# Save as CSV
write_csv(coef_table_quad, "figures/coef_table_quad_model.csv")

# Optional: coefficient plot (dot-and-whisker)
coef_plot_quad <- coef_table_quad %>%
  filter(term != "(Intercept)") %>%
  mutate(term = fct_reorder(term, estimate)) %>%
  ggplot(aes(x = estimate, y = term)) +
  geom_point() +
  geom_errorbarh(aes(xmin = estimate - 1.96*std.error,
                     xmax = estimate + 1.96*std.error), height = 0.2) +
  labs(title = "Coefficient Estimates (Quadratic Model)", x = "Estimate", y = "") +
  theme_minimal()

ggsave("figures/coef_plot_quad_model.png", coef_plot_quad, width = 7, height = 5, dpi = 300)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
